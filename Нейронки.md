### 1. **Углубленное понимание архитектур нейронных сетей**

#### a. **Продвинутые архитектуры нейронных сетей**

- [x] **ResNet и другие остаточные сети**: Понятие остаточных соединений (skip connections) для предотвращения затухания градиента и обучения более глубоких сетей.
- [x] **DenseNet**: Сети с плотными соединениями, где каждый слой получает входные данные от всех предыдущих слоев.
- [x] **Inception-сети**: Использование нескольких свёрточных фильтров различных размеров на одном уровне сети для захвата разных аспектов данных.

#### b. **Рекуррентные нейронные сети (RNN) и их расширения**

- [x] **LSTM и GRU**: Долгосрочные краткосрочные память и затухающие рекуррентные единицы для решения проблемы затухания градиента в RNN.
- **Attention и Self-Attention механизмы**: Улучшение фокуса модели на важных частях входных данных, применяемое в трансформерах и современных NLP задачах.

### 2. **Методы регуляризации и оптимизации**

- [x] **Dropout**: Метод регуляризации, предотвращающий переобучение за счет случайного исключения нейронов во время тренировки.
- [x] **Batch Normalization**: Стабилизация и ускорение обучения за счет нормализации выходных данных слоев.
- [x] **Early Stopping**: Метод остановки тренировки, когда качество модели на валидационной выборке начинает ухудшаться.

### 3. **Методы обучения и обратного распространения**

- **Оптимизационные алгоритмы**:
    
    - **SGD и его модификации (Momentum, Nesterov)**: Базовые методы оптимизации и их улучшения для ускорения сходимости.
    - **Adam, RMSprop**: Адаптивные методы градиентного спуска, которые используют момент и текущие значения градиентов для автоматической настройки скорости обучения.
- [x] **Backpropagation Through Time (BPTT)**: Метод обратного распространения ошибки для рекуррентных нейронных сетей, учитывающий временные зависимости.
    

### 4. **Интерпретация и объяснимость нейронных сетей**

- **Интерпретируемость моделей**: Методы анализа вклада входных признаков, такие как Grad-CAM для CNN, LIME, SHAP для общей интерпретации моделей.
- **Теория объяснимости**: Изучение причинно-следственных связей и их влияние на решения, принимаемые моделями ИИ.

### 5. **Продвинутые техники обучения**

- [x] **Трансферное обучение**: Использование предобученных моделей для новых задач, что снижает потребность в большом количестве данных и вычислительных ресурсов.
- **Метаобучение (обучение тому, как учиться)**: Подходы, позволяющие моделям быстрее адаптироваться к новым задачам с небольшим количеством данных.
- **Обучение с подкреплением (Reinforcement Learning)**: Методы, при которых агент обучается взаимодействовать с окружением и получать награду за выполнение определённых действий.

### 6. **Этика и безопасность в ИИ**

- **Этика в машинном обучении**: Анализ предвзятости моделей, проблемы конфиденциальности и безопасности данных.
- **Безопасность и устойчивость моделей**: Методы противодействия атакам на модели, оценка устойчивости к изменениям в данных.